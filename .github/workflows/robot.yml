name: Extragere È™i Procesare Date Nivologice
on:
  schedule:
    - cron: '0 6,14,20 * * *'  # 06:00, 14:00, 20:00 UTC (09:00, 17:00, 23:00 RomÃ¢nia)
  workflow_dispatch:

jobs:
  extraget-nivologic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 lxml pytz

    - name: Extract È™i Parse Date Nivologice
      run: |
        cat > extract_and_parse.py << 'EOF'
        import requests
        import re
        import json
        from datetime import datetime
        import pytz
        
        # Mapping masive -> zone
        ZONE_MAPPING = {
            'bucegi': 'meridionali',
            'fagaras': 'meridionali', 
            'piatra-craiului': 'meridionali',
            'retezat': 'meridionali',
            'parang': 'meridionali',
            'tarcu': 'meridionali',
            'godeanu': 'meridionali',
            'cindrel': 'meridionali',
            'cozia': 'meridionali',
            'iezer': 'meridionali',
            'baiului': 'meridionali',
            'ciucas': 'meridionali',
            'rodnei': 'orientali',
            'ceahlau': 'orientali',
            'calimani': 'orientali',
            'hasmas': 'orientali',
            'maramuresului': 'orientali',
            'apuseni': 'occidentali'
        }
        
        def download_buletin():
            """DescarcÄƒ buletinul de pe situl ANM"""
            urls = [
                'https://www.meteoromania.ro/anm2/php/anm2_buletin_nivologic.php',
                'https://www.meteoromania.ro/anm2/php/anm2_buletin_nivologic.php?id=buletin'
            ]
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
            }
            
            for url in urls:
                try:
                    response = requests.get(url, headers=headers, timeout=30)
                    if response.status_code == 200 and len(response.text) > 500:
                        return response.text
                except Exception as e:
                    print(f"Eroare descÄƒrcare {url}: {e}")
                    continue
            
            return None
        
        def extract_text_from_html(html_content):
            """Extrage textul din HTML"""
            from bs4 import BeautifulSoup
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # EliminÄƒ script, style, etc.
            for tag in soup(['script', 'style', 'meta', 'link']):
                tag.decompose()
            
            text = soup.get_text(separator=' ')
            
            # CurÄƒÈ›Äƒ textul
            text = re.sub(r'\s+', ' ', text)
            text = text.strip()
            
            return text
        
        def extract_valabilitate(text):
            """Extrage perioada de valabilitate"""
            text_lower = text.lower()
            
            luni_ro = {
                'ianuarie': '01', 'februarie': '02', 'martie': '03',
                'aprilie': '04', 'mai': '05', 'iunie': '06', 
                'iulie': '07', 'august': '08', 'septembrie': '09',
                'octombrie': '10', 'noiembrie': '11', 'decembrie': '12'
            }
            
            # Pattern: "valabil pentru perioada 14-15 ianuarie 2026"
            for luna_text, luna_num in luni_ro.items():
                pattern = rf'valabil[Äƒ]?\s+(?:pentru|Ã®n|pe)?\s*perioada?\s+(\d{{1,2}})\s*[-â€“â€”]\s*(\d{{1,2}})\s+{luna_text}(?:\s+(\d{{4}}))?'
                match = re.search(pattern, text_lower)
                if match:
                    an = match.group(3) if match.group(3) else str(datetime.now().year)
                    zi_start = match.group(1).zfill(2)
                    zi_end = match.group(2).zfill(2)
                    
                    return {
                        'de_la': f"{an}-{luna_num}-{zi_start}",
                        'pana_la': f"{an}-{luna_num}-{zi_end}"
                    }
            
            # Pattern alternativ: "valabil: 14.01.2026 - 15.01.2026"
            pattern = r'valabil[Äƒ]?\s*[:\s]+(\d{1,2})[.\/-](\d{1,2})[.\/-](\d{4})\s*[-â€“â€”]\s*(\d{1,2})[.\/-](\d{1,2})[.\/-](\d{4})'
            match = re.search(pattern, text_lower)
            if match:
                return {
                    'de_la': f"{match.group(3)}-{match.group(2).zfill(2)}-{match.group(1).zfill(2)}",
                    'pana_la': f"{match.group(6)}-{match.group(5).zfill(2)}-{match.group(4).zfill(2)}"
                }
            
            return None
        
        def find_masiv_section(text, masiv, zona):
            """GÄƒseÈ™te secÈ›iunea specificÄƒ masivului"""
            text_lower = text.lower()
            
            # Variante masiv
            masiv_variants = [
                masiv.lower(),
                masiv.lower().replace('-', ' '),
                masiv.lower().replace('-', '')
            ]
            
            # CautÄƒ masivul specific
            for variant in masiv_variants:
                pos = text_lower.find(variant)
                if pos != -1:
                    # Extrage ~1500 caractere Ã®n jurul menÈ›iunii
                    start = max(0, pos - 300)
                    section = text[start:start + 1500]
                    return section
            
            # Fallback: cautÄƒ zona
            zona_search = f'carpaÈ›i {zona}' if zona else ''
            if zona_search:
                pos = text_lower.find(zona_search)
                if pos != -1:
                    start = max(0, pos - 200) 
                    section = text[start:start + 1200]
                    return section
            
            # Ultimate fallback
            return text[:2000]
        
        def extract_avalanche_risk_by_altitude(section_text, altitude_target=2000):
            """Extrage riscul pe baza altitudinii"""
            text_norm = section_text.lower()
            text_norm = re.sub(r'\s+', ' ', text_norm)
            
            debug_info = {
                'altitude_target': altitude_target,
                'sections_found': [],
                'section_selected': 'fallback - Ã®ntreg textul',
                'content_analyzed': text_norm[:200] + '...'
            }
            
            # STEP 1: IdentificÄƒ secÈ›iunile pe altitudine
            altitude_sections = []
            
            altitude_patterns = [
                r'la\s+peste\s+(\d+)\s*m[:\s]+([^Â§]+?)(?=(?:sub\s+\d+\s*m|la\s+peste\s+\d+\s*m|risc\s+\w+\s*\(\d\)|$))',
                r'sub\s+(\d+)\s*m[:\s]+([^Â§]+?)(?=(?:la\s+peste\s+\d+\s*m|sub\s+\d+\s*m|risc\s+\w+\s*\(\d\)|$))'
            ]
            
            for pattern in altitude_patterns:
                matches = re.finditer(pattern, text_norm, re.IGNORECASE)
                for match in matches:
                    alt_threshold = int(match.group(1))
                    content = match.group(2)
                    is_above = 'peste' in match.group(0).lower()
                    
                    altitude_sections.append({
                        'threshold': alt_threshold,
                        'is_above': is_above,
                        'content': content
                    })
                    
                    debug_info['sections_found'].append({
                        'threshold': alt_threshold,
                        'type': 'peste' if is_above else 'sub',
                        'preview': content[:100] + '...'
                    })
            
            # STEP 2: GÄƒseÈ™te secÈ›iunea potrivitÄƒ
            selected_content = ''
            
            if altitude_sections:
                for section in altitude_sections:
                    threshold = section['threshold']
                    is_above = section['is_above']
                    
                    if is_above and altitude_target > threshold:
                        selected_content = section['content']
                        debug_info['section_selected'] = f"peste {threshold}m (È›inta: {altitude_target}m)"
                        break
                    elif not is_above and altitude_target <= threshold:
                        selected_content = section['content'] 
                        debug_info['section_selected'] = f"sub {threshold}m (È›inta: {altitude_target}m)"
                        break
            
            if not selected_content:
                selected_content = section_text
                debug_info['section_selected'] = 'fallback - Ã®ntreg textul'
            
            debug_info['content_analyzed'] = selected_content[:200] + '...'
            
            # STEP 3: Extrage riscul
            patterns = {
                5: [
                    r'risc\s*u?l?\s*(?:de\s+)?avalan[È™s][aÄƒ]\s*[:\-]?\s*5',
                    r'risc\s*[:\-]?\s*5',
                    r'grad\s*5',
                    r'foarte\s+ridicat'
                ],
                4: [
                    r'risc\s*u?l?\s*(?:de\s+)?avalan[È™s][aÄƒ]\s*[:\-]?\s*4', 
                    r'risc\s*[:\-]?\s*4',
                    r'grad\s*4',
                    r'ridicat(?!\s+foarte)',
                    r'risc\s+mare\s*\(\s*4\s*\)'
                ],
                3: [
                    r'risc\s*u?l?\s*(?:de\s+)?avalan[È™s][aÄƒ]\s*[:\-]?\s*3',
                    r'risc\s*[:\-]?\s*3', 
                    r'grad\s*3',
                    r'[iÃ®]nsemnat',
                    r'risc\s+[iÃ®]nsemnat\s*\(\s*3\s*\)'
                ],
                2: [
                    r'risc\s*u?l?\s*(?:de\s+)?avalan[È™s][aÄƒ]\s*[:\-]?\s*2',
                    r'risc\s*[:\-]?\s*2',
                    r'grad\s*2', 
                    r'moderat',
                    r'risc\s+moderat\s*\(\s*2\s*\)'
                ],
                1: [
                    r'risc\s*u?l?\s*(?:de\s+)?avalan[È™s][aÄƒ]\s*[:\-]?\s*1',
                    r'risc\s*[:\-]?\s*1',
                    r'grad\s*1',
                    r'sc[aÄƒ]zut',
                    r'redus'
                ]
            }
            
            for level in [5, 4, 3, 2, 1]:
                for pattern in patterns[level]:
                    match = re.search(pattern, selected_content, re.IGNORECASE)
                    if match:
                        debug_info['pattern_gasit'] = pattern
                        debug_info['match'] = match.group(0)
                        return level, debug_info
            
            debug_info['pattern_gasit'] = 'niciunul'
            return 0, debug_info
        
        def extract_strat_zapada(section_text):
            """Extrage detalii strat zÄƒpadÄƒ"""
            details = {}
            
            # Grosime
            match = re.search(r'grosime[a]?\s*(?:strat[ul]*)?[:\s]*(\d+)\s*(?:-\s*(\d+))?\s*cm', section_text, re.IGNORECASE)
            if match:
                details['grosime_cm'] = int(match.group(2)) if match.group(2) else int(match.group(1))
            
            # Calitate
            if re.search(r'zÄƒpadÄƒ proaspÄƒtÄƒ|nou-depus', section_text, re.IGNORECASE):
                details['calitate'] = 'proaspÄƒtÄƒ'
            elif re.search(r'zÄƒpadÄƒ veche|compactatÄƒ', section_text, re.IGNORECASE):
                details['calitate'] = 'veche/compactatÄƒ'
            elif re.search(r'crustÄƒ|regelatÄƒ', section_text, re.IGNORECASE):
                details['calitate'] = 'crustÄƒ/regelatÄƒ'
            
            # PlÄƒci de vÃ¢nt
            if re.search(r'plÄƒci|placi', section_text, re.IGNORECASE):
                details['placi_vant'] = True
                
            return details if details else None
        
        def process_all_massifs(text, valabilitate):
            """ProceseazÄƒ toate masivele pentru diferite altitudini"""
            risk_names = {
                0: 'Necunoscut',
                1: 'ScÄƒzut', 
                2: 'Moderat',
                3: 'ÃŽnsemnat',
                4: 'Ridicat',
                5: 'Foarte ridicat'
            }
            
            altitudes = [1200, 1500, 1800, 2000, 2200, 2500]
            results = {}
            
            for masiv, zona in ZONE_MAPPING.items():
                results[masiv] = {
                    'zona': zona,
                    'altitudini': {}
                }
                
                section = find_masiv_section(text, masiv, zona)
                strat_zapada = extract_strat_zapada(section)
                
                for altitude in altitudes:
                    nivel_risc, debug_info = extract_avalanche_risk_by_altitude(section, altitude)
                    
                    results[masiv]['altitudini'][altitude] = {
                        'risc_nivel': nivel_risc,
                        'risc_text': risk_names[nivel_risc],
                        'debug_info': debug_info
                    }
                
                # AdaugÄƒ detalii comune pentru masiv
                results[masiv]['strat_zapada'] = strat_zapada
                results[masiv]['sectiune_preview'] = section[:300] + '...'
            
            return results
        
        def main():
            print("ðŸ”„ DescÄƒrcare buletin nivologic...")
            html_content = download_buletin()
            
            if not html_content:
                print("âŒ Eroare la descÄƒrcarea buletinului")
                return
            
            print("ðŸ“„ Extragere text din HTML...")
            text = extract_text_from_html(html_content)
            
            if len(text) < 500:
                print("âŒ Text prea scurt sau invalid")
                return
            
            print("ðŸ“… Extragere perioadÄƒ valabilitate...")
            valabilitate = extract_valabilitate(text)
            
            print("ðŸ”ï¸ Procesare date pentru toate masivele...")
            massifs_data = process_all_massifs(text, valabilitate)
            
            # StructurÄƒ finalÄƒ JSON
            output_data = {
                'metadata': {
                    'generated_at': datetime.now(pytz.timezone('Europe/Bucharest')).isoformat(),
                    'valabilitate': valabilitate,
                    'sursa': 'ANM - AdministraÈ›ia NaÈ›ionalÄƒ de Meteorologie',
                    'text_length': len(text),
                    'versiune_parser': '2.0'
                },
                'masive': massifs_data,
                'text_complet': text  # Pentru debugging
            }
            
            # SalveazÄƒ JSON
            with open('date_meteo.json', 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            # SalveazÄƒ È™i textul brut pentru compatibilitate
            with open('date_meteo.txt', 'w', encoding='utf-8') as f:
                f.write(text)
            
            print("âœ… Date salvate Ã®n date_meteo.json È™i date_meteo.txt")
            print(f"ðŸ“Š Procesate {len(massifs_data)} masive")
            if valabilitate:
                print(f"ðŸ“… Valabil: {valabilitate['de_la']} â†’ {valabilitate['pana_la']}")
        
        if __name__ == "__main__":
            main()
        EOF
        
        python extract_and_parse.py

    - name: Commit È™i Push modificÄƒri
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add .
        git commit -m "Update date nivologice: $(date '+%Y-%m-%d %H:%M')" || exit 0
        git push
